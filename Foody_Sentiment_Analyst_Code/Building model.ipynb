{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad59e46f-290c-4a36-aed8-48846fa37b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628112a9-0052-4299-b91d-76d4cd62df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b852c8-2d11-47dd-b70c-f7b858d9fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be49019e-b466-4c9b-a5af-666ac8152a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gà tắm mắm  phô mai kéo sợi siêu ngon  giá mềm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gà bq hàn  phô mai kéo sợi siêu ngon  giá mềm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gà với khoai tây quá mặn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mình vừa đặt 1 phần gà 92k và vô cùng thất vọn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>đồ ăn chuẩn vị hàn quốc  ngon giá cả hợp lí</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   review_text_clean  label\n",
       "0     gà tắm mắm  phô mai kéo sợi siêu ngon  giá mềm      1\n",
       "1      gà bq hàn  phô mai kéo sợi siêu ngon  giá mềm      1\n",
       "2                           gà với khoai tây quá mặn      0\n",
       "3  mình vừa đặt 1 phần gà 92k và vô cùng thất vọn...      0\n",
       "4        đồ ăn chuẩn vị hàn quốc  ngon giá cả hợp lí      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('/Users/docongluong/Downloads/food_clean.xlsx', index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c2f9fc-c0db-4a82-9cb4-fe4f77ed51cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gà tắm mắm  phô mai kéo sợi siêu ngon  giá mềm',\n",
       "       'gà bq hàn  phô mai kéo sợi siêu ngon  giá mềm',\n",
       "       'gà với khoai tây quá mặn', ...,\n",
       "       'quán nằm trong đường trần quang diệu  mà phải đi sâu xíu  nếu không có ai giới thiệu chắc cũng không biết được  nhưng vì quán ngon và cũng khá nổi tiếng trong khu vực bình thuỷ nên là bạn bè hay rủ rê mình lại đấy \\nđồ ăn ngon  nêm nếm đậm đà  đặc biệt ở đây phục vụ rất nhiều các món làm từ mực   đặc sản của quán  cũng là gương mặt thương hiệu của quán  ngoài ra  quán còn phục vụ rất nhiều món khác thích hợp cho những buổi nhâm nhi cùng bạn bè hay gia đình  \\nvề giá cả thì phải chăng và hợp lý so với thị trường  \\nnói chung là  ngon  ',\n",
       "       'trời mưa lạnh thèm ăn bún bò  lần đầu lại đây mua ăn  lúc đó là 5rưỡi chiều  mua một tái nạm đem về  hết chả  nước để trong bọc nguội ngắt luôn  8 lát thịt vừa tái vừa nạm  35k  không hành tây  về nhà nấu sôi rồi ngồi ăn thấy hết thèm  hết ngon miệng  không biết có phải tại đến không đúng thời điểm hay không  nước nguội như vậy  ai mua đem đi đâu không có bếp nấu lại thì coi như nghỉ ăn rồi còn gì ',\n",
       "       'quán chủ yếu là phở nhưng mình lại thích bún bò hơn    ngon   mình gọi tô bún bò không để giò heo   để bò và bò viên   tô bún nhìn rất hấp dẫn   ngon   hương vị đậm đà   bò với bò viên ngon   bò viên nhai sần sật không pha bột nhiều   tương xay cũng rất ngon   thêm 1 tí sa tế vào là đỉnh luôn   ngon     quán khá sạch sẽ   thoáng   mấy cô bán cũng vui vẻ   ngon  '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = np.array(df['review_text_clean'])\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85141f3f-8786-4dfa-b700-be50d6f367e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=None)\n",
    "bag_of_words = tfidf.fit_transform(text_data)  # Sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df3bf70-06f3-49fa-b5ed-6ebbac5bf411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31534, 17241)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = bag_of_words\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "991ca6cf-b5e7-4c66-9a96-7b1087dfa681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31534,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(df['label'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0afcd05a-5218-4127-9d35-f878ca0edc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<5x17241 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 272 stored elements in Compressed Sparse Row format>,\n",
       " array([1, 1, 1, 1, 0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22e41238-71fd-44ac-be62-044903db9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_n_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions on training and test sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate accuracy and metrics\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "    \n",
    "    recall = report['1']['recall']\n",
    "    precision = report['1']['precision']\n",
    "    f1 = report['1']['f1-score']\n",
    "    \n",
    "    print(f'-- Accuracy train: {train_accuracy:.4f}')\n",
    "    print(f'-- Accuracy test: {test_accuracy:.4f}')\n",
    "    print(f'-- Recall: {recall:.4f}, Precision: {precision:.4f}, F1: {f1:.4f}')\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3e94f2f-6d4d-4e4e-8f0c-9cc0c6d69a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Accuracy train: 0.9032\n",
      "-- Accuracy test: 0.8850\n",
      "-- Recall: 0.8921, Precision: 0.9514, F1: 0.9208\n",
      "Confusion Matrix:\n",
      "[[2049  323]\n",
      " [ 765 6324]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79      2372\n",
      "           1       0.95      0.89      0.92      7089\n",
      "\n",
      "    accuracy                           0.89      9461\n",
      "   macro avg       0.84      0.88      0.86      9461\n",
      "weighted avg       0.90      0.89      0.89      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = LogisticRegression(class_weight='balanced')\n",
    "build_n_evaluate_model(model1, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d117a57a-f96b-4e02-a542-521af805e70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16432, number of negative: 5641\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 215978\n",
      "[LightGBM] [Info] Number of data points in the train set: 22073, number of used features: 2887\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.744439 -> initscore=1.069169\n",
      "[LightGBM] [Info] Start training from score 1.069169\n",
      "[LightGBM] [Info] Number of positive: 16432, number of negative: 5641\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.184737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 215978\n",
      "[LightGBM] [Info] Number of data points in the train set: 22073, number of used features: 2887\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.744439 -> initscore=1.069169\n",
      "[LightGBM] [Info] Start training from score 1.069169\n",
      "-- Accuracy train: 0.9286\n",
      "-- Accuracy test: 0.8828\n",
      "-- Recall: 0.9004, Precision: 0.9406, F1: 0.9201\n",
      "Confusion Matrix:\n",
      "[[1969  403]\n",
      " [ 706 6383]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78      2372\n",
      "           1       0.94      0.90      0.92      7089\n",
      "\n",
      "    accuracy                           0.88      9461\n",
      "   macro avg       0.84      0.87      0.85      9461\n",
      "weighted avg       0.89      0.88      0.89      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
    "\n",
    "# Initialize LGBMClassifier with scale_pos_weight parameter before SMOTE\n",
    "model2 = lgb.LGBMClassifier(scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "# Train the model on the original imbalanced data\n",
    "model2.fit(X_train, y_train)\n",
    "# Evaluate the model using the `build_n_evaluate_model()` function on the resampled data\n",
    "build_n_evaluate_model(model2, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b8bf106-5ca5-4d2d-9b53-273f47c28d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Accuracy train: 0.9994\n",
      "-- Accuracy test: 0.8700\n",
      "-- Recall: 0.9819, Precision: 0.8633, F1: 0.9188\n",
      "Confusion Matrix:\n",
      "[[1270 1102]\n",
      " [ 128 6961]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.54      0.67      2372\n",
      "           1       0.86      0.98      0.92      7089\n",
      "\n",
      "    accuracy                           0.87      9461\n",
      "   macro avg       0.89      0.76      0.80      9461\n",
      "weighted avg       0.87      0.87      0.86      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "build_n_evaluate_model(model3, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2eec574-aa00-469f-9ae9-fad9d4434401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Accuracy train: 0.9206\n",
      "-- Accuracy test: 0.8850\n",
      "-- Recall: 0.8983, Precision: 0.9455, F1: 0.9213\n",
      "Confusion Matrix:\n",
      "[[2005  367]\n",
      " [ 721 6368]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79      2372\n",
      "           1       0.95      0.90      0.92      7089\n",
      "\n",
      "    accuracy                           0.89      9461\n",
      "   macro avg       0.84      0.87      0.85      9461\n",
      "weighted avg       0.89      0.89      0.89      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model4 = SVC(class_weight='balanced', kernel='linear')\n",
    "build_n_evaluate_model(model4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6aec5101-9112-4a00-ba18-43e1b27cf4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 03:41:21.173311: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.8459 - loss: 0.4355\n",
      "Epoch 2/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9141 - loss: 0.2446\n",
      "Epoch 3/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9389 - loss: 0.1774\n",
      "Epoch 4/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9613 - loss: 0.1174\n",
      "Epoch 5/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9755 - loss: 0.0780\n",
      "Epoch 6/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9840 - loss: 0.0512\n",
      "Epoch 7/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9884 - loss: 0.0347\n",
      "Epoch 8/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9931 - loss: 0.0235\n",
      "Epoch 9/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9953 - loss: 0.0164\n",
      "Epoch 10/10\n",
      "\u001b[1m690/690\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.0103\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "** Model on Unbalanced Data **\n",
      "Accuracy: 0.8772\n",
      "Confusion Matrix:\n",
      "[[1850  522]\n",
      " [ 640 6449]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      2372\n",
      "           1       0.93      0.91      0.92      7089\n",
      "\n",
      "    accuracy                           0.88      9461\n",
      "   macro avg       0.83      0.84      0.84      9461\n",
      "weighted avg       0.88      0.88      0.88      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import keras\n",
    "from keras import layers\n",
    "# Step 1: Train the model on unbalanced data (Original training data)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Define the MLP Neural Network model\n",
    "model_nn = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_dim=X_train.shape[1]),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with class weights (on unbalanced data)\n",
    "model_nn.fit(X_train, y_train, epochs=10, batch_size=32, class_weight=class_weight_dict, verbose=1)\n",
    "\n",
    "# Evaluate the model on unbalanced test set\n",
    "y_pred_nn = (model_nn.predict(X_test) > 0.5).astype(\"int32\")\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "conf_matrix_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "class_report_nn = classification_report(y_test, y_pred_nn)\n",
    "\n",
    "print(\"** Model on Unbalanced Data **\")\n",
    "print(f\"Accuracy: {accuracy_nn:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_nn)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_nn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a76ac6eb-f94b-4354-a713-7d3fd453f7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 16432, 0: 5641})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0b13053-2997-4059-aede-c5e8bc3cb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE()\n",
    "X_resample, y_resample = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "525accf2-17cc-41a9-a0ee-0a325a17d89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 16432, 0: 16432})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1536bc37-496f-4a08-b790-849b47bc904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Accuracy train: 0.9246\n",
      "-- Accuracy test: 0.8860\n",
      "-- Recall: 0.9072, Precision: 0.9386, F1: 0.9226\n",
      "Confusion Matrix:\n",
      "[[1951  421]\n",
      " [ 658 6431]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2372\n",
      "           1       0.94      0.91      0.92      7089\n",
      "\n",
      "    accuracy                           0.89      9461\n",
      "   macro avg       0.84      0.86      0.85      9461\n",
      "weighted avg       0.89      0.89      0.89      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1_o = LogisticRegression(class_weight='balanced')\n",
    "model1_o.fit(X_resample, y_resample)\n",
    "build_n_evaluate_model(model1_o, X_resample, y_resample, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19f2e94b-e4af-4c99-96ef-d2a50bec99dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16432, number of negative: 16432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.383440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 270198\n",
      "[LightGBM] [Info] Number of data points in the train set: 32864, number of used features: 3503\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 16432, number of negative: 16432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.327846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 270198\n",
      "[LightGBM] [Info] Number of data points in the train set: 32864, number of used features: 3503\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "-- Accuracy train: 0.9387\n",
      "-- Accuracy test: 0.8864\n",
      "-- Recall: 0.9233, Precision: 0.9250, F1: 0.9241\n",
      "Confusion Matrix:\n",
      "[[1841  531]\n",
      " [ 544 6545]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      2372\n",
      "           1       0.92      0.92      0.92      7089\n",
      "\n",
      "    accuracy                           0.89      9461\n",
      "   macro avg       0.85      0.85      0.85      9461\n",
      "weighted avg       0.89      0.89      0.89      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scale_pos_weight = (len(y_resample) - sum(y_resample)) / sum(y_resample)\n",
    "\n",
    "# Initialize LGBMClassifier with scale_pos_weight parameter\n",
    "model2_o = lgb.LGBMClassifier(scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "# Train the model using the resampled data from SMOTE\n",
    "model2_o.fit(X_resample, y_resample)\n",
    "\n",
    "# Evaluate the model using the `build_n_evaluate_model()` function\n",
    "build_n_evaluate_model(model2_o, X_resample, y_resample, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "736765dc-ac04-4d0e-b5f3-02d2cca22436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Accuracy train: 0.9995\n",
      "-- Accuracy test: 0.8808\n",
      "-- Recall: 0.9571, Precision: 0.8917, F1: 0.9233\n",
      "Confusion Matrix:\n",
      "[[1548  824]\n",
      " [ 304 6785]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.65      0.73      2372\n",
      "           1       0.89      0.96      0.92      7089\n",
      "\n",
      "    accuracy                           0.88      9461\n",
      "   macro avg       0.86      0.80      0.83      9461\n",
      "weighted avg       0.88      0.88      0.88      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3_o = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model3_o.fit(X_resample, y_resample)\n",
    "build_n_evaluate_model(model3_o, X_resample, y_resample, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "879cb4d6-0208-4e74-b5ea-af11da4c1af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Accuracy train: 0.9399\n",
      "-- Accuracy test: 0.8892\n",
      "-- Recall: 0.9161, Precision: 0.9348, F1: 0.9253\n",
      "Confusion Matrix:\n",
      "[[1919  453]\n",
      " [ 595 6494]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79      2372\n",
      "           1       0.93      0.92      0.93      7089\n",
      "\n",
      "    accuracy                           0.89      9461\n",
      "   macro avg       0.85      0.86      0.86      9461\n",
      "weighted avg       0.89      0.89      0.89      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4_o = SVC(class_weight='balanced', kernel='linear')\n",
    "model4_o.fit(X_resample, y_resample)\n",
    "build_n_evaluate_model(model4_o, X_resample, y_resample, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62fb65a8-3496-4c63-9b47-265c18c5a093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.9941 - loss: 0.0208\n",
      "Epoch 2/10\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.9965 - loss: 0.0113\n",
      "Epoch 3/10\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.9965 - loss: 0.0105\n",
      "Epoch 4/10\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.9968 - loss: 0.0091\n",
      "Epoch 5/10\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.9970 - loss: 0.0084\n",
      "Epoch 6/10\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.9973 - loss: 0.0087\n",
      "Epoch 7/10\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.9974 - loss: 0.0070\n",
      "Epoch 8/10\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.0055\n",
      "Epoch 9/10\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.0042\n",
      "Epoch 10/10\n",
      "\u001b[1m1027/1027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.9979 - loss: 0.0065\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\n",
      "** Model after SMOTE **\n",
      "Accuracy: 0.8706\n",
      "Confusion Matrix:\n",
      "[[1805  567]\n",
      " [ 657 6432]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75      2372\n",
      "           1       0.92      0.91      0.91      7089\n",
      "\n",
      "    accuracy                           0.87      9461\n",
      "   macro avg       0.83      0.83      0.83      9461\n",
      "weighted avg       0.87      0.87      0.87      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Retrain the model on SMOTE-resampled data\n",
    "model_nn.fit(X_resample, y_resample, epochs=10, batch_size=32, class_weight=class_weight_dict, verbose=1)\n",
    "\n",
    "# Evaluate the model after SMOTE\n",
    "y_pred_nn_smote = (model_nn.predict(X_test) > 0.5).astype(\"int32\")\n",
    "accuracy_nn_smote = accuracy_score(y_test, y_pred_nn_smote)\n",
    "conf_matrix_nn_smote = confusion_matrix(y_test, y_pred_nn_smote)\n",
    "class_report_nn_smote = classification_report(y_test, y_pred_nn_smote)\n",
    "\n",
    "print(\"\\n** Model after SMOTE **\")\n",
    "print(f\"Accuracy: {accuracy_nn_smote:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_nn_smote)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_nn_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fd50f03-1272-4047-a843-0883c8fd7737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16432, number of negative: 16432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.330333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 270198\n",
      "[LightGBM] [Info] Number of data points in the train set: 32864, number of used features: 3503\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 13145, number of negative: 13146\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.266886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 238429\n",
      "[LightGBM] [Info] Number of data points in the train set: 26291, number of used features: 3188\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499981 -> initscore=-0.000076\n",
      "[LightGBM] [Info] Start training from score -0.000076\n",
      "[LightGBM] [Info] Number of positive: 13145, number of negative: 13146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.304511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 237950\n",
      "[LightGBM] [Info] Number of data points in the train set: 26291, number of used features: 3176\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499981 -> initscore=-0.000076\n",
      "[LightGBM] [Info] Start training from score -0.000076\n",
      "[LightGBM] [Info] Number of positive: 13146, number of negative: 13145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.289020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 238095\n",
      "[LightGBM] [Info] Number of data points in the train set: 26291, number of used features: 3170\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000076\n",
      "[LightGBM] [Info] Start training from score 0.000076\n",
      "[LightGBM] [Info] Number of positive: 13146, number of negative: 13145\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.282950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 238349\n",
      "[LightGBM] [Info] Number of data points in the train set: 26291, number of used features: 3184\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000076\n",
      "[LightGBM] [Info] Start training from score 0.000076\n",
      "[LightGBM] [Info] Number of positive: 13146, number of negative: 13146\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.281634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 237872\n",
      "[LightGBM] [Info] Number of data points in the train set: 26292, number of used features: 3175\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m917s\u001b[0m 4s/step\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step\n",
      "\n",
      "** Stacking Model after SMOTE **\n",
      "Accuracy: 0.8944\n",
      "Confusion Matrix:\n",
      "[[1698  674]\n",
      " [ 325 6764]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.77      2372\n",
      "           1       0.91      0.95      0.93      7089\n",
      "\n",
      "    accuracy                           0.89      9461\n",
      "   macro avg       0.87      0.84      0.85      9461\n",
      "weighted avg       0.89      0.89      0.89      9461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model, epochs=10, batch_size=32):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Fit the Keras model\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions using the Keras model\n",
    "        return np.argmax(self.model.predict(X), axis=1)\n",
    "\n",
    "# Wrap your MLP model with the custom wrapper\n",
    "model_nn_sklearn = KerasClassifierWrapper(model_nn, epochs=10, batch_size=32)\n",
    "\n",
    "base_models = [\n",
    "    ('lr', model1_o),  # Logistic Regression\n",
    "    ('lgbm', model2_o),  # LightGBM\n",
    "    ('rf', model3_o),  # Random Forest\n",
    "    ('svc', model4_o),  # Support Vector Classifier\n",
    "    ('mlp', model_nn_sklearn)   # MLP wrapped with the custom KerasClassifierWrapper\n",
    "]\n",
    "\n",
    "# Define the meta-model (Logistic Regression)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Create the Stacking Classifier\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Train the stacking model on the resampled data (after SMOTE)\n",
    "stacking_model.fit(X_resample, y_resample)\n",
    "\n",
    "# Evaluate the stacking model\n",
    "y_pred_stacking = stacking_model.predict(X_test)\n",
    "accuracy_stacking = accuracy_score(y_test, y_pred_stacking)\n",
    "conf_matrix_stacking = confusion_matrix(y_test, y_pred_stacking)\n",
    "class_report_stacking = classification_report(y_test, y_pred_stacking)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\n** Stacking Model after SMOTE **\")\n",
    "print(f\"Accuracy: {accuracy_stacking:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_stacking)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_stacking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba67402-c022-4e5d-b84e-b00288d306a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
